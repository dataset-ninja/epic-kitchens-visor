**Epic Kitchens VISOR Dataset** is a dataset for semantic segmentation, object detection, and identification tasks. It is applicable or relevant across various domains. Also, it is used in the food industry. 

The dataset consists of 50729 images with 367002 labeled objects belonging to 305 different classes including *hand:right*, *hand:left*, *hob*, and other: *pan*, *sink*, *knife*, *board:chopping*, *tap*, *spoon*, *bowl*, *plate*, *water*, *cupboard*, *pot*, *lid*, *sponge*, *spatula*, *bag*, *fridge*, *package*, *drawer*, *fork*, *bottle*, *cup*, *onion*, *box*, *rack:drying*, *meat*, and 277 more.

Images in the Epic Kitchens VISOR dataset have pixel-level semantic segmentation annotations. There are 10125 (20% of the total) unlabeled images (i.e. without annotations). There are 3 splits in the dataset: *train* (32857 images), *test* (10125 images), and *val* (7747 images). Alternatively, the dataset could be split into 2 video sequences: ***video*** (50729 images) and ***subsequence*** (40604 images). Additionally, labels marked with its ***instance***, ***exhaustively annotated*** and ***in contact*** tags. Explore it in Supervisely labelling tool. The dataset was released in 2022 by the <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University of Bristol, United Kingdom</span>, <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University of Michigan, United States</span>, and <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University of Toronto, Canada</span>.

Here is a visualized example for randomly selected sample classes:

[Dataset classes](https://github.com/dataset-ninja/epic-kitchens-visor/raw/main/visualizations/classes_preview.webm)
